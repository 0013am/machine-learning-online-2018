{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, SimpleRNN,LSTM, Activation, Bidirectional\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('dataset/train_emoji.csv',header=None)\n",
    "test = pd.read_csv('dataset/test_emoji.csv',header=None)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "\n",
    "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":grinning_face_with_big_eyes:\",\n",
    "                    \"3\": \":disappointed_face:\",\n",
    "                    \"4\": \":fork_and_knife:\",\n",
    "                    \"5\": \":hundred_points:\",\n",
    "                    \"6\": \":fire:\",\n",
    "                    \"7\": \":face_blowing_a_kiss:\",\n",
    "                    \"8\": \":chestnut:\",\n",
    "                    \"9\":\":flexed_biceps:\"\n",
    "                   }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emoji.EMOJI_UNICODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ù§Ô∏è\n",
      "‚öæ\n",
      "üòÉ\n",
      "üòû\n",
      "üç¥\n",
      "üíØ\n",
      "üî•\n",
      "üòò\n",
      "üå∞\n",
      "üí™\n"
     ]
    }
   ],
   "source": [
    "for e in emoji_dictionary.values():\n",
    "    print(emoji.emojize(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again üòû\n",
      "I am proud of your achievements üòÉ\n",
      "It is the worst day in my life üòû\n",
      "Miss you so much ‚ù§Ô∏è\n",
      "food is life üç¥\n"
     ]
    }
   ],
   "source": [
    "data  = train.values\n",
    "for i in range(5):\n",
    "    print(data[i][0],emoji.emojize(emoji_dictionary[str(data[i][1])]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 4)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train[0]\n",
    "Y_train = train[1]\n",
    "\n",
    "X_test = test[0]\n",
    "Y_test = test[1]\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ix in range(X_train.shape[0]):\n",
    "    X_train[ix] = X_train[ix].split()\n",
    "    \n",
    "for ix in range(X_test.shape[0]):\n",
    "    X_test[ix] = X_test[ix].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yt = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'talk', 'to', 'me', 'again'] [0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0],Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove.6B.50d.txt',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype='float')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['food'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddingMatrix(sentences):\n",
    "    embedding_matrix = np.zeros((X_train.shape[0],10,50))\n",
    "    \n",
    "    for ix in range(sentences.shape[0]):\n",
    "        for ij in range(len(sentences[ix])):\n",
    "            embedding_matrix[ix][ij] = embeddings_index[X_train[ix][ij].lower()]\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_train = np.zeros((X_train.shape[0], 10, 50))\n",
    "embedding_matrix_test = np.zeros((X_test.shape[0], 10, 50))\n",
    "\n",
    "for ix in range(X_train.shape[0]):\n",
    "    for ij in range(len(X_train[ix])):\n",
    "        embedding_matrix_train[ix][ij] = embeddings_index[X_train[ix][ij].lower()]\n",
    "        \n",
    "for ix in range(X_test.shape[0]):\n",
    "    for ij in range(len(X_test[ix])):\n",
    "        try:\n",
    "            embedding_matrix_test[ix][ij] = embeddings_index[X_test[ix][ij].lower()]   \n",
    "        except:\n",
    "            embedding_matrix_test[ix][ij] = np.zeros((50,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 10, 50) (56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix_train.shape,embedding_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 29,765\n",
      "Trainable params: 29,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#model.add(LSTM(64, input_shape=(10,50), return_sequences=True,recurrent_dropout=0.1))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(LSTM(64,input_shape=(10,50), return_sequences=False,recurrent_dropout=0.1))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 118 samples, validate on 14 samples\n",
      "Epoch 1/200\n",
      "118/118 [==============================] - 1s 10ms/step - loss: 1.6110 - acc: 0.2373 - val_loss: 1.5842 - val_acc: 0.3571\n",
      "Epoch 2/200\n",
      "118/118 [==============================] - 0s 321us/step - loss: 1.5642 - acc: 0.4068 - val_loss: 1.5932 - val_acc: 0.2143\n",
      "Epoch 3/200\n",
      "118/118 [==============================] - 0s 406us/step - loss: 1.5473 - acc: 0.3898 - val_loss: 1.6026 - val_acc: 0.2143\n",
      "Epoch 4/200\n",
      "118/118 [==============================] - 0s 397us/step - loss: 1.5190 - acc: 0.4153 - val_loss: 1.6072 - val_acc: 0.2143\n",
      "Epoch 5/200\n",
      "118/118 [==============================] - 0s 372us/step - loss: 1.4896 - acc: 0.4153 - val_loss: 1.6049 - val_acc: 0.2143\n",
      "Epoch 6/200\n",
      "118/118 [==============================] - 0s 296us/step - loss: 1.4576 - acc: 0.4407 - val_loss: 1.6066 - val_acc: 0.2143\n",
      "Epoch 7/200\n",
      "118/118 [==============================] - 0s 363us/step - loss: 1.4452 - acc: 0.3983 - val_loss: 1.5948 - val_acc: 0.2143\n",
      "Epoch 8/200\n",
      "118/118 [==============================] - 0s 330us/step - loss: 1.4215 - acc: 0.4237 - val_loss: 1.5746 - val_acc: 0.1429\n",
      "Epoch 9/200\n",
      "118/118 [==============================] - 0s 380us/step - loss: 1.3600 - acc: 0.4915 - val_loss: 1.5486 - val_acc: 0.1429\n",
      "Epoch 10/200\n",
      "118/118 [==============================] - 0s 440us/step - loss: 1.3204 - acc: 0.4746 - val_loss: 1.5003 - val_acc: 0.2857\n",
      "Epoch 11/200\n",
      "118/118 [==============================] - 0s 296us/step - loss: 1.2485 - acc: 0.5085 - val_loss: 1.4429 - val_acc: 0.2857\n",
      "Epoch 12/200\n",
      "118/118 [==============================] - ETA: 0s - loss: 1.1197 - acc: 0.593 - 0s 355us/step - loss: 1.2159 - acc: 0.5508 - val_loss: 1.4162 - val_acc: 0.2857\n",
      "Epoch 13/200\n",
      "118/118 [==============================] - 0s 431us/step - loss: 1.1359 - acc: 0.6017 - val_loss: 1.3964 - val_acc: 0.2857\n",
      "Epoch 14/200\n",
      "118/118 [==============================] - 0s 338us/step - loss: 1.0552 - acc: 0.5763 - val_loss: 1.2848 - val_acc: 0.3571\n",
      "Epoch 15/200\n",
      "118/118 [==============================] - 0s 363us/step - loss: 0.9684 - acc: 0.6441 - val_loss: 1.2280 - val_acc: 0.5000\n",
      "Epoch 16/200\n",
      "118/118 [==============================] - 0s 685us/step - loss: 0.9560 - acc: 0.6186 - val_loss: 1.2554 - val_acc: 0.4286\n",
      "Epoch 17/200\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.8381 - acc: 0.7458 - val_loss: 1.0456 - val_acc: 0.6429\n",
      "Epoch 18/200\n",
      "118/118 [==============================] - 0s 372us/step - loss: 0.7908 - acc: 0.7797 - val_loss: 1.3069 - val_acc: 0.5000\n",
      "Epoch 19/200\n",
      "118/118 [==============================] - 0s 541us/step - loss: 0.7260 - acc: 0.7966 - val_loss: 1.0982 - val_acc: 0.6429\n",
      "Epoch 20/200\n",
      "118/118 [==============================] - 0s 406us/step - loss: 0.6872 - acc: 0.7966 - val_loss: 1.0741 - val_acc: 0.6429\n",
      "Epoch 21/200\n",
      "118/118 [==============================] - 0s 414us/step - loss: 0.6495 - acc: 0.8220 - val_loss: 1.0527 - val_acc: 0.6429\n",
      "Epoch 22/200\n",
      "118/118 [==============================] - 0s 634us/step - loss: 0.5747 - acc: 0.8390 - val_loss: 1.2230 - val_acc: 0.5714\n",
      "Epoch 23/200\n",
      "118/118 [==============================] - 0s 414us/step - loss: 0.6180 - acc: 0.8136 - val_loss: 0.8980 - val_acc: 0.6429\n",
      "Epoch 24/200\n",
      "118/118 [==============================] - 0s 380us/step - loss: 0.5236 - acc: 0.7881 - val_loss: 0.8598 - val_acc: 0.6429\n",
      "Epoch 25/200\n",
      "118/118 [==============================] - 0s 380us/step - loss: 0.4798 - acc: 0.8644 - val_loss: 0.9255 - val_acc: 0.7143\n",
      "Epoch 26/200\n",
      "118/118 [==============================] - 0s 406us/step - loss: 0.4122 - acc: 0.8814 - val_loss: 0.9196 - val_acc: 0.6429\n",
      "Epoch 27/200\n",
      "118/118 [==============================] - 0s 355us/step - loss: 0.4234 - acc: 0.8814 - val_loss: 0.7877 - val_acc: 0.6429\n",
      "Epoch 28/200\n",
      "118/118 [==============================] - 0s 363us/step - loss: 0.3100 - acc: 0.9237 - val_loss: 0.8384 - val_acc: 0.6429\n",
      "Epoch 29/200\n",
      "118/118 [==============================] - 0s 524us/step - loss: 0.3616 - acc: 0.8983 - val_loss: 0.9260 - val_acc: 0.6429\n",
      "Epoch 30/200\n",
      "118/118 [==============================] - 0s 389us/step - loss: 0.3415 - acc: 0.8898 - val_loss: 0.7960 - val_acc: 0.6429\n",
      "Epoch 31/200\n",
      "118/118 [==============================] - 0s 347us/step - loss: 0.3621 - acc: 0.8898 - val_loss: 0.5133 - val_acc: 0.7143\n",
      "Epoch 32/200\n",
      "118/118 [==============================] - 0s 406us/step - loss: 0.3270 - acc: 0.8983 - val_loss: 0.7221 - val_acc: 0.6429\n",
      "Epoch 33/200\n",
      "118/118 [==============================] - 0s 397us/step - loss: 0.4477 - acc: 0.8475 - val_loss: 0.7190 - val_acc: 0.7857\n",
      "Epoch 34/200\n",
      "118/118 [==============================] - 0s 338us/step - loss: 0.3788 - acc: 0.8814 - val_loss: 0.9492 - val_acc: 0.7143\n",
      "Epoch 35/200\n",
      "118/118 [==============================] - 0s 338us/step - loss: 0.4421 - acc: 0.8644 - val_loss: 1.1267 - val_acc: 0.6429\n",
      "Epoch 36/200\n",
      "118/118 [==============================] - 0s 321us/step - loss: 0.4022 - acc: 0.8644 - val_loss: 0.4800 - val_acc: 0.7143\n",
      "Epoch 37/200\n",
      "118/118 [==============================] - 0s 296us/step - loss: 0.3201 - acc: 0.8898 - val_loss: 0.5715 - val_acc: 0.7143\n",
      "Epoch 38/200\n",
      "118/118 [==============================] - 0s 473us/step - loss: 0.3009 - acc: 0.9068 - val_loss: 0.8133 - val_acc: 0.7143\n",
      "Epoch 39/200\n",
      "118/118 [==============================] - 0s 592us/step - loss: 0.2384 - acc: 0.9407 - val_loss: 0.8635 - val_acc: 0.7143\n",
      "Epoch 40/200\n",
      "118/118 [==============================] - 0s 347us/step - loss: 0.3069 - acc: 0.8729 - val_loss: 0.7315 - val_acc: 0.7143\n",
      "Epoch 41/200\n",
      "118/118 [==============================] - 0s 330us/step - loss: 0.2621 - acc: 0.9153 - val_loss: 0.6832 - val_acc: 0.6429\n",
      "Epoch 42/200\n",
      "118/118 [==============================] - 0s 296us/step - loss: 0.2238 - acc: 0.9237 - val_loss: 0.8590 - val_acc: 0.6429\n",
      "Epoch 43/200\n",
      "118/118 [==============================] - 0s 355us/step - loss: 0.1960 - acc: 0.9407 - val_loss: 0.8296 - val_acc: 0.7143\n",
      "Epoch 44/200\n",
      "118/118 [==============================] - 0s 321us/step - loss: 0.1995 - acc: 0.9407 - val_loss: 0.6950 - val_acc: 0.7143\n",
      "Epoch 45/200\n",
      "118/118 [==============================] - 0s 321us/step - loss: 0.1533 - acc: 0.9576 - val_loss: 0.6924 - val_acc: 0.7143\n",
      "Epoch 46/200\n",
      "118/118 [==============================] - 0s 355us/step - loss: 0.1474 - acc: 0.9831 - val_loss: 0.6298 - val_acc: 0.7143\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint # save the best model, fight overfiitting\n",
    "from keras.callbacks import EarlyStopping #save time\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "earlystop = EarlyStopping(monitor='val_acc',patience=1)\n",
    "\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "\n",
    "hist = model.fit(embedding_matrix_train,Y_train,\n",
    "                epochs = 200, batch_size=32,shuffle=True,validation_split=0.1,callbacks=[checkpoint,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(embedding_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 2 3 2 2 3 2 4 2 1 2 3 3 1 3 3 2 3 2 3 0 4 0 3 3 2 0 4 2 0 1 3 2 0 1 2\n",
      " 3 4 2 1 0 0 1 2 2 3 2 3 1 3 0 3 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(sum(pred==t))/embedding_matrix_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_classes(embedding_matrix_test)\n",
    "t = np.array(test[1])\n",
    "float(sum(pred==t))/embedding_matrix_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sen = \"it is a great movie!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-29-e4c08fa49f1e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-29-e4c08fa49f1e>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    for w in test_sen.\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for w in test_sen.\n",
    "embeddings = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
