{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "- Simple Tree like structure, model makes a decision at every node\n",
    "- Useful in simple tasks\n",
    "- One of the most popular algorithm\n",
    "\n",
    "### Why decision trees are popular?\n",
    "   - Easy to interpret and present\n",
    "   - Well defined Logic, mimic human level thought\n",
    "   - Random Forests, Ensembles of decision trees are more powerful classifiers\n",
    "\n",
    "### Features \n",
    "Feature values are preferred to be **categorical**. If the values are continuous then they are discretized prior to building the model.\n",
    "\n",
    "## Algorithm to Build Decision Trees\n",
    "- CART (Classification and Regression Trees) → uses Gini Index(Classification) as metric.\n",
    "- ID3 (Iterative Dichotomiser 3) → uses Entropy function and Information gain as metrics\n",
    "\n",
    "#### Selecting the 'Right' Attributes\n",
    " The primary challenge in the decision tree implementation is to identify which attributes do we need to consider as the root node and each level. Handling this is know the attributes selection. We have different attributes selection measure to identify the attribute which can be considered as the root note at each level.\n",
    "\n",
    "The popular attribute selection measures:\n",
    "\n",
    "    1. Information gain\n",
    "    2. Gini index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
